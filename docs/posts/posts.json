[
  {
    "path": "posts/27-mirai-240/",
    "title": "mirai 2.4.0",
    "description": "First Class Async and High-Performance Computing",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2025-06-26",
    "categories": [],
    "contents": "\n\nContents\nState of Async in the Ecosystem\nWhat’s New: cluster_config() HPC Integration\nReal-World Examples\nWhy This Matters for HPC Users\nAdditional Enhancements\nGetting Started\nLooking Forward\n\nmirai 2.4.0: First Class Async and High-Performance ComputingState of Async in the Ecosystem\nI gave a talk at Posit Conf last year (2024) on bringing first-class (real, event-driven) async to R, jointly with Will Landau, a long-time collaborator. At the time his crew package was the only practical way to use mirai in High-Performance Computing (HPC) environments, and it continues to be a great solution for HPC and cloud platforms, powering all distributed targets pipelines.\nSince then, we at Posit have been delivering this vision to you. First we now have event-driven async in our popular packages httr2 and ellmer. We’ve also added event-driven file watching capability to auto-reload Shiny in its latest (1.11.0) release. But did you know that the seed for all these capabilities originated with mirai?\nmirai is now recognized as a primary async backend for Shiny (in 1.11.0), and we’re updating our promises documentation as this post goes to publication to provide additional support for users. It also powers parallel execution in purrr, with a shiny new in_parallel() adverb that’s in a version on the verge of being released. It’s also the async evaluator behind the @async tag in plumber2 (still experimental at the posit-dev GitHub organization).\nAs mirai now underpins much of this ecosystem, it was about time that HPC got first-class treatment within mirai itself. We’re really pleased to bring this to you, and we’re really excited with what we’ve been seeing in terms of how efficiently mirai scales.\nWhat’s New: cluster_config() HPC Integration\nThe headline feature of mirai 2.4.0 is the addition of cluster_config(), a flexible launcher designed specifically for HPC environments. This allows R users to easily deploy mirai daemons across HPC clusters using familiar resource management systems.\nSupported HPC Resource Managers\nThe new cluster_config() supports all major HPC schedulers:\nSlurm (using sbatch)\nSGE (Sun Grid Engine, using qsub)\nTorque/PBS (using qsub)\nLSF (Load Sharing Facility, using bsub)\nSimple Yet Powerful Configuration\nThe beauty of cluster_config() lies in its simplicity. With just three parameters, you can configure complex HPC deployments:\ncluster_config(\n  command = \"sbatch\",    # The scheduler command\n  options = \"\",          # Scheduler-specific options\n  rscript = \"Rscript\"    # Path to R executable\n)\nReal-World Examples\nHere’s how you can use cluster_config() with different HPC systems:\nSlurm Configuration\n# Configure for Slurm with resource specifications\nslurm_config <- cluster_config(\n  command = \"sbatch\",\n  options = \"#SBATCH --job-name=mirai\n             #SBATCH --mem=10G\n             #SBATCH --output=job.out\n             module load R/4.5.0\",\n  rscript = file.path(R.home(\"bin\"), \"Rscript\")\n)\n\n# Launch daemons using the configuration\ndaemons(\n  n = 100,\n  url = host_url(),\n  remote = slurm_config\n)\nSGE Configuration\n# Configure for SGE\nsge_config <- cluster_config(\n  command = \"qsub\",\n  options = \"#$ -N mirai\n             #$ -l mem_free=10G\n             #$ -o job.out\n             module load R/4.5.0\"\n)\nLSF Configuration\n# Configure for LSF\nlsf_config <- cluster_config(\n  command = \"bsub\",\n  options = \"#BSUB -J mirai\n             #BSUB -M 10000\n             #BSUB -o job.out\n             module load R/4.5.0\"\n)\nWhy This Matters for HPC Users\nThe introduction of cluster_config() represents a significant milestone for R users working in HPC environments. Previously, setting up distributed computing across cluster nodes required manual script writing and configuration. Now, mirai provides a unified R interface that abstracts away the complexity, while maintaining the full power and flexibility of setting any available options.\nKey Benefits:\nUnified Interface: One function works across all major HPC schedulers\nNative Integration: No need for external scripts or complex setup procedures\nFlexible Configuration: Full access to scheduler-specific options and commands\nSeamless Scaling: Easy deployment from single nodes to hundreds of cores\nResource Management: Support for memory limits, logging and other requirements\nAdditional Enhancements\nBeyond the headline cluster_config() launcher, version 2.4.0 introduces several important improvements:\nDeveloper-Friendly Features\nNew require_daemons() Function:\nProvides an elegant way to prompt users to set up daemons when needed, complete with clickable function links (leveraging the cli package where available).\nBehavioural Improvements\nEnhanced Daemon Management:\nDaemons now exit immediately when the host process terminates.\nProtection against recursive local daemon spawning during mirai_map() operations.\nSimplified Remote Launches:\nlaunch_remote() commands are now simpler, as daemons retrieve RNG streams directly from the dispatcher rather than requiring a unique rs argument. This allows easier manual deployment.\nGetting Started\nTo take advantage of these new features, update to mirai 2.4.0:\ninstall.packages(\"mirai\")\nFor HPC users, the path to distributed computing with mirai has never been clearer:\nlibrary(mirai)\n\n# Configure your HPC environment\nconfig <- cluster_config(\n  command = \"sbatch\",  # or qsub, bsub as appropriate\n  options = \"your_scheduler_options_here\"\n)\n\n# Launch distributed daemons\ndaemons(n = 10, url = host_url(), remote = config)\n\n# Start computing at scale\nresults <- mirai_map(1:1000, expensive_function)\nLooking Forward\nWe hope that mirai 2.4.0 allows HPC computing to become more accessible to a broader range of R users, democratizing high-performance computing capabilities across the community.\nWhether you’re processing large datasets, running complex simulations, or conducting extensive model training, mirai 2.4.0’s HPC integration provides the tooling you need to scale your R workflows efficiently and elegantly.\nThe mirai of async computing in R is here, and it’s more accessible than ever.\nLearn more about mirai and its capabilities at the official documentation or explore the source code on GitHub.\n\n\n\n",
    "preview": "posts/27-mirai-240/images/cms.jpg",
    "last_modified": "2025-07-13T13:15:56+01:00",
    "input_file": "mirai-240.knit.md"
  },
  {
    "path": "posts/26-mirai-230/",
    "title": "mirai 2.3.0",
    "description": "Advancing Async Computing in R",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2025-05-23",
    "categories": [],
    "contents": "\n\nContents\nWhat Makes mirai Unique?\nKey Enhancements in Version 2.3.0\nIntegration with the R Ecosystem\nGetting Started with mirai 2.3.0\nLooking Forward\n\nmirai 2.3.0: Advancing Async Computing in RThe R ecosystem continues to evolve with powerful tools for modern computing challenges, and mirai stands at the forefront of asynchronous evaluation frameworks. This latest release brings significant enhancements that solidify mirai’s position as the most sophisticated approach to async computing in R.\nWhat Makes mirai Unique?\nmirai (ミライ, Japanese for “future”) represents a paradigm shift in how R handles asynchronous operations. Built on the robust foundation of nanonext and NNG (Nanomsg Next Gen), mirai offers:\nTrue event-driven architecture with non-polling promises\nSeamless distributed computing over modern, scalable and secure networking\nSupport for reference objects like Arrow Tables and torch tensors\nAsync-first by design e.g. async rather than just parallel map\nUnlike traditional parallel computing approaches in R, mirai handles many more tasks than available processes (and requires no file system storage) through its inherently queued architecture.\nKey Enhancements in Version 2.3.0\n1. Enhanced Timeout Capabilities\nThe most notable behavioural change is the upgrade to mirai()’s .timeout argument. mirai now automatically cancels ongoing operations upon timeout. This feature provides better control over long-running tasks and prevents resource wastage from abandoned computations.\n# Timeout now actively cancels the operation\nm <- mirai({\n  long_compute_intensive_task()\n}, .timeout = 5000)  # Cancels after 5 seconds\n2. Improved Serialization Configuration\nserial_config() now accepts vector arguments to register multiple custom serialization configurations simultaneously.\nThis enhancement simplifies working with diverse data types across distributed systems, for example both Arrow Tables and Polars DataFrames.\n3. Comprehensive Network Discovery\nhost_url() has been upgraded to return all local IP addresses, named by network interface. This provides a more robust solution for distributed computing setups, especially in complex network environments:\n# Returns all available interfaces\nhost_url()\n# Example output:\n# eth0: \"tcp://192.168.1.100:5555\"\n# wlan0: \"tcp://192.168.1.101:5555\"\n4. New Utility Functions\nThree new functions enhance the developer experience:\nregister_serial(): allows package authors to register serialization configurations for all daemons() calls\non_daemon(): indicates whether evaluation is occurring within a mirai call on a daemon\ndaemons_set(): checks if daemons are set for a given compute profile\n5. Extended Support for HPC Environments\nFor HPC environments, daemons() now supports initial synchronization exceeding 10 seconds.\nThis enhancement is particularly valuable for large-scale distributed computing setups where network latency or resource provisioning may require longer connection times.\nIntegration with the R Ecosystem\nOfficial R Parallel Cluster Type\nAs of R 4.5, mirai is now one of the official base R parallel cluster types.\n# Create a miraiCluster directly\ncl <- parallel::makeCluster(6, type = \"MIRAI\")\nSeamless Shiny\nmirai’s promises integrate seamlessly with Shiny applications, enabling truly responsive user interfaces.\nDeveloped in collaboration with Joe Cheng (creator of Shiny), it’s the only event-driven solution that fully integrates with Shiny’s capabilities, and also scales to complex apps with many users Link to vignette examples.\nPowers Purrr\nmirai’s mirai_map() provides the underlying implementation for purrr’s new purrr::map(.parallel = TRUE) and friends (currently in the development version). Purrr is one of the core tidyverse packages, and a respected functional programming tookit that is depended upon by data scientists and developers alike.\nScience at Scale\nmirai users benefit from a longstanding collaboration with Will Landau at Eli Lily, where his targets package adopted crew (built on mirai) as its default HPC backend. The life sciences industry runs heavy-duty pipelines across HPC and cloud environments on a constant basis, providing real life assurance of mirai’s reliability.\nGetting Started with mirai 2.3.0\nInstallation is straightforward:\ninstall.packages(\"mirai\")\nBasic usage remains elegantly simple:\nlibrary(mirai)\n\n# Launch background daemons\ndaemons(6)\n\n# Evaluate asynchronously\nm <- mirai({\n  expensive_computation()\n})\n\n# Continue other work...\n\n# Retrieve result when needed\nresult <- m$data\nLooking Forward\nmirai represents more than an incremental improvement — it’s a testament to R’s evolution as a modern computing platform. With its sophisticated architecture, robust error handling, and seamless integration with contemporary R workflows, mirai enables developers to build scalable, responsive applications that leverage distributed computing resources effectively.\nThe combination of simplicity in design and power in execution makes mirai the go-to solution for:\nHigh-performance computing in research environments\nProduction-grade Shiny applications requiring responsiveness at scale\nData engineering pipelines with complex computational requirements\nMachine learning workflows involving large models and datasets\nAs the R ecosystem continues to modernize, mirai stands as a cornerstone technology, bridging the gap between R’s statistical heritage and the demands of contemporary distributed computing.\nFor more information, visit the mirai website or explore the package on CRAN or GitHub. Join the community in shaping the future of async computing in R.\n\n\n\n",
    "preview": "posts/26-mirai-230/images/mirai-static.png",
    "last_modified": "2025-06-26T23:52:56+01:00",
    "input_file": {},
    "preview_width": 1200,
    "preview_height": 630
  },
  {
    "path": "posts/25-mirai-v2/",
    "title": "mirai v2.0",
    "description": "Continuous Innovation",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2025-02-07",
    "categories": [],
    "contents": "\n\nContents\n1. Easier distributed computing\n2. Mirai cancellation\n3. Tidyverse {purrr} integration\n\n\n\n\nIt’s been some months since my last update on mirai. That hasn’t of course meant that things have stood still, far from it.\nFirst I’d like to make a special point of thanking Posit for their support for the project. I’m really grateful for their contribution in so many ways, and I’m sure that this partnership will continue to yield benefits for the R community as a whole.\nI’d like to briefly review some of what I consider the most important updates here: (i) easier distributed computing, (ii) mirai cancellation, and (iii) tidyverse {purrr} integration.\n1. Easier distributed computing\nThe old mirai v1.x dispatcher used an approach where you specified the number of daemons [= background parallel processes] and this was then fixed, and daemons dialled in to their assigned, specific URL. Of course this all just happened in the background for local daemons, so you wouldn’t need to worry about this. All you’d do is:\n\n\ndaemons(6)\n\n\nUnless, that is, you had tasks to send to other machines.\nmirai’s launchers still tried to make it relatively easy, but if you needed to manually spin up a daemon, for example in a cloud instance, you’d have to be sure that it dialled in to the correct address. Now no longer. All daemons just use the same URL. This also means that there’s no longer a pre-set limit, making it much easier to add or remove daemons at any time, dynamically scaling with demand.\nOn a quick technical aside, distributed computing previously relied on a websocket layer over HTTP, and now this has been completely stripped away to enable direct TCP-level communications, which is both faster and more reliable.\nThe operation of ssh_config() has also been simplified, making SSH-tunnelled connections over the local network really easy. It’s now possible to create standalone configurations that are just a list of parameters, like the below:\n\n\nssh_config(remotes = \"ssh://192.168.1.10:22\", port = 5555, tunnel = TRUE)\n\n$command\n[1] \"ssh\"\n\n$args\n$args[[1]]\n[1] \"-R 5555:127.0.0.1:5555\"       \"-o ConnectTimeout=10 -fTp 22\"\n[3] \"192.168.1.10\"                 \".\"                           \n\n\n$rscript\n[1] \"Rscript\"\n\n$quote\n[1] TRUE\n\nWhat this means is that for any computer where you have SSH access, mirai can now use it as a backend on which to launch daemons. It’s not only simpler, but also safer, as there’s no need to open any ports or change any firewall settings. This topic alone merits its own blog post, so I won’t go into any more detail for now. Do check out the documentation for further details in the meantime.\n2. Mirai cancellation\nThis has been a long-requested feature in a Shiny context. Shiny can send a long-running ExtendedTask to run code asynchronously using mirai. In fact, mirai is the only solution that interfaces with the ‘later’ package at the C level to provide truly event-driven promises in Shiny, or any other context for that matter.\nAs Shiny provides a primarily interactive experience, it’s an environment where the user can often change their mind and not want to wait for the results, for example, by choosing to cancel.\nPreviously, it’s been possible for the interface to act ‘as if’ it were cancelled. However, on the daemon, whereever that is, the instruction would still be ongoing. This can be problematic for two reasons: (i) it still occupies resources, and can do so for an extended period if the task is long-running, or (ii) the operation has side effects e.g. it records a transaction in a database, where we don’t actually want it to.\nNow in mirai v2.0 and newer, when a mirai is cancelled using stop_mirai(), an interrupt signal is sent to the daemon where the work is being done. This stops the task and frees the daemon for the next task.\n\n\ndaemons(1)\n\n[1] 1\n\nSys.time()\n\n[1] \"2025-02-09 00:10:20 GMT\"\n\nm <- mirai({ Sys.sleep(60); Sys.time() })\nm\n\n< mirai [] >\n\nstop_mirai(m)\nm[]\n\n'errorValue' int 20 | Operation canceled\n\n# if stop_mirai() did not stop evaluation of 'm', 'm2' would be blocked for 60s\nm2 <- mirai(Sys.time())\nm2[]\n\n[1] \"2025-02-09 00:10:20 GMT\"\n\n# we can see from the timestamp that it was not blocked\n\ndaemons(0)\n\n[1] 0\n\nFor how to implement cancellation of a Shiny ExtendedTask, please see this example.\n3. Tidyverse {purrr} integration\nThe purrr package is a cornerstone of the tidyverse. It is the functional programming toolkit. As of the current development version (post-1.0.4), mirai now provides purrr with parallel map capabilities.\nThis means that all purrr users can now use existing purrr functions such as purrr::map(), just specifying .parallel = TRUE to take advantage of mirai under the hood. For example:\n\n\ndaemons(6)\n\n[1] 6\n\nmtcars |> purrr::map_dbl(sum, .parallel = TRUE)\n\n     mpg      cyl     disp       hp     drat       wt     qsec \n 642.900  198.000 7383.100 4694.000  115.090  102.952  571.160 \n      vs       am     gear     carb \n  14.000   13.000  118.000   90.000 \n\ndaemons(0)\n\n[1] 0\n\nThe advantage of purrr::map() over mirai_map() is that it’s designed to offer the same consistency and guarantees as non-parallel purrr. It’s also really convenient to parallelize existing code as you only need to add .parallel = TRUE to the existing call.\nThe advantage of mirai_map() over purrr::map() is that it offers full async, in that you are free to choose whether to wait for the results / when to collect them, or even to have each map iteration trigger a promise.\nA fun fact is that for all the parallel functions enabled in purrr - including map(), imap(), pmap() and all the variations thereof - they ultimately all end up as a call to mirai_map() under the hood. This attests to the power and versatility of this one single function, undoubtedly one of the major innovations for mirai to date.\nDo give development purrr a spin. Any issues or comments are very welcome at the mirai repository: https://github.com/shikokuchuo/mirai.\n\nFinally, to conclude: the mirai project has emerged from 2024 technically much stronger, and is well-positioned to build on its success in 2025. We greatly appreciate the support of our users and developers. Please feel free to share your success stories at https://github.com/shikokuchuo/mirai/discussions.\n\n\n\n",
    "preview": "posts/25-mirai-v2/mirai-v2_files/figure-html5/index-1.png",
    "last_modified": "2025-02-09T00:10:24+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/24-conditional-linkingto/",
    "title": "Conditional LinkingTo in R",
    "description": "Innovations Supporting Shiny",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2024-07-02",
    "categories": [
      "R"
    ],
    "contents": "\n\nContents\nBig Picture\nThe Specific Case\nA Solution\nConcluding Remarks\n\n\n\n\nBig Picture\nThe success of the R language can at least in part be attributed to the many thousands of packages that extend the functionality of base R. There is a mature system of ‘Depends/Imports’ for hard dependencies and ‘Suggests/Enhances’ for soft or conditional dependencies. In this way, the current ecosystem of interlinked packages has developed over time.\nHowever, this has only been the case for R packages importing or calling exported R functions from other packages.\nMany packages provide interfaces at a lower level via the R_RegisterCCallable / R_GetCCallable mechanism, and these are almost always more performant where using them is possible (just avoiding re-entry back into R itself can be significant for fairly atomic operations). In other cases, it may only make sense to interface at the C level.\nIf this is the case, then there is only the ‘LinkingTo’ approach described in ‘Writing R Extensions’ 5.4.3 Linking to native routines in other packages, which also requires the use of ‘Imports’ to load the dependent package for R_GetCCallable to work. In other words, there is seemingly only the option to add a hard dependency.\nIn many cases this is simply not feasible. Taking for example code that provides a binding to a C library - this can be expected to have many uses in any number of contexts. Even if there is a compelling use case in any one such context, it would rarely make sense for this (perhaps zero-dependency) package to add a dependency, as this encumbers all downstream users of the package.\nThe unfortunate result of this state of affairs is that many such packages remain siloed. Sometimes package authors attempt to ‘vendor’ or copy across the source code of another to avoid a dependency.\nThe Specific Case\nmirai is a minimalist asynchronous evaluation framework for R. It is an async launcher of Shiny ExtendedTasks (the hot new feature of 2024), highlighted by Joe Cheng (CTO, Posit and creator of Shiny) himself.\nAs part of its integration with Shiny, mirai goes one step further - as a collaborative effort, it implements next-generation promises that are completely event-driven and non-polling - the first of its kind anywhere in R.\nThis is only available through mirai as it is powered by a tight integration of nanonext’s own concurrency framework with the later event loop at the C level. This results in zero-latency promise resolution, enabling more responsive, and also massively-scalable Shiny apps. It allows crazy possibilities, such as firing off hundreds of thousands of mirai promises.\nThe Shiny use case was compelling, hence leading to its adoption in the first place. However, nanonext/mirai is also used in many other scientific contexts in industry, where it acts as the High Performance Computing back-end for targets through crew. nanonext is so incredibly lightweight that adding later as a dependency doubled its load time, which in turn affected the performance of short-lived mirai processes.\nA Solution\nnanonext linked to later in the usual way in its 1.0.0 release. However as of v1.1.1, ‘conditional LinkingTo’ has been achieved, with later only appearing as a ‘suggests’ dependency of nanonext.\nThe method employed by nanonext consists only of the following steps:\nDefine a C function pointer with the correct signature, along with a dummy function ->\nAssign the function pointer to the dummy function during package initialization ->\nAt the point where the function is called, check if the function pointer points to the dummy function ->\nIf so, construct and evaluate a call to load the dependent package ->\nThen assign the function pointer to the real function obtained by R_GetCCallable ->\nThe later package / shared object is hence only loaded if it is actually used. This has the happy consequence of reducing the load time of nanonext by up to half. Furthermore, later (with its dependencies) is now not required at all for the installation of nanonext itself, which remains a zero-dependency package.\nConcluding Remarks\nThe above presents a viable method for constructing ‘conditional LinkingTo’.\nIt should be noted that for packages to pass ‘R CMD check’, care should be taken to write tests conditional upon the presence of the soft dependency. Also, where relevant, the failure of step 4 (for example if the package is not installed) should also be considered and handled.\nWe hope that this sparks some new ideas for package authors, opening up avenues for innovation and collaboration, with positive external benefits to the R ecosystem as a whole.\n\n\n\n",
    "preview": "posts/24-conditional-linkingto/conditional-linkingto_files/figure-html5/index-1.png",
    "last_modified": "2025-02-07T12:50:38+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/23-mirai-quality-of-life-updates/",
    "title": "mirai - Quality of Life Updates",
    "description": "Ten Small Improvements",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2024-06-25",
    "categories": [
      "R"
    ],
    "contents": "\n\n\n\nThe last couple of quarters have been somwhat of a whirlwind for mirai. Whether that’s been working with Joe Cheng (CTO, Posit and creator of the Shiny framework) to implement the next generation of promises, introducing mirai_map() as an ‘async-native’ map function, or reaching 1.0.0 release and being accepted for full presentations at useR!2024 and Posit::conf. But the flagship features can all wait to be reviewed in depth.\nHere, I want to recap on some of the little things that have changed since around v0.12 released in January of this year. Things that really improve the quality of life for new and loyal mirai users alike. Sometimes it’s these that make the biggest difference, as we strive to take a somewhat thoughtful approach to incoporating new features and requests. I’ve picked 10 items, in no particular order, with the only proviso being that they are small enough not to merit their own blog post.\n1. Minimalism\nThe print method for a mirai has been pared back to one line. There is simply no reason to take up any more screen real estate.\nMore recently, it actually indicates if a mirai has resoved or not. This is possible as the check is so optimised (on the nanosecond scale) that it doesn’t very well make sense not to include it.\n\n\n(m <- mirai({})) # unresolved\n\n< mirai [] >\n\n\n\n(call_mirai(m)) # resolved\n\n< mirai [$data] >\n\n2. Unseen Improvements\nSince the start of the year, the package has been made robust to memory leaks along error paths. We’re confident in making this claim as test coverage is 100% for the package - rounded up (:\nThis was a massive engineering effort over the Christmas break, mostly in the underlying nanonext package, that included delving into the depths of R’s C API for gems like R_UnwindProtect(), and verifying the results using ‘Valgrind’. The entire effort was inspired by this post by Hiroaki Yutani: https://yutani.rbind.io/post/dont-panic-we-can-unwind/\n3. More Signalling\nThose familiar with the operation of mirai know that it adopts a completely event-driven approach, relying on synchronization primitives and events, such as message completion, being signalled from different threads. There are no loops which constantly check for updates. This means we achieve both zero latency and no resource utilization while waiting, which was always a tradeoff between the two using the dated polling approach.\nBut even more signalling?! Well, actually the ability to pass a signal value such as tools::SIGINT to the ‘autoexit’ parameter of daemon(). This is a feature that makes mirai more fit for certain use cases.\ndaemons(8, autoexit = tools::SIGINT)\nThe default behaviour for daemons is that even if the host process ends, daemons finish what they are doing before exiting. This is perfect for tasks such as checkpointing deep learning models where you want such tasks to finish regardless of what happens in the main process, precisely because you know the main process is liable to instability.\nHowever for working on a lengthy linear pipeline performing Bayesian statistics on expensive cloud servers, you would want such processes to end immediately if the main process dies. This is now possible by supplying an appropriate interrupt.\n4. Less surprising by default\nThe ... and .args arguments to mirai() previously kind of fulfilled the same purpose. And .args could awkardly take both a named or unnamed list.\nNow, they have clearly delineated uses. In fact, for simplicity we now encourage only the use of ....\nThis is as using ... won’t give surprises.\nBy design, mirai evaluation occurs in a new clean environment, where .args parameters are put. For those used to working with scripts within the global environment and expecting behaviours to carry over in mirai evaluations, this could cause surprises when supplying functions defined with variables that live in the global environment. As ... parameters are explicitly placed into the global environment of the daemon processes, the expected behaviour then carries over.\nHowever, by enabling .... and .args to do different things, the interface becomes more parsimonious and allows mirai to retain the flexibility and best of both worlds. All while still trying to be a little less surprising by default…\n5. Environment convenience\nThe ... and .args arguments to mirai() now both accept an environment as the first/only argument.\nThis allows conveniently passing all the objects defined in a local environment or a script, without having to list each one individually. A pertinent use case is with Shiny ExtendedTask:\ntask <- shiny::ExtendedTask$new(\n  function(a, b, c, x, y, z) mirai({ a * b * c + x + y - z }, environment())\n)\nAll the variables defined by the anonymous function arguments are passed through to the mirai when it is invoked.\n6. Vectorization\nThe functions unresolved(), call_mirai(), collect_mirai() and stop_mirai() now all accept a list of mirai. This is ostensibly for compatibility with mirai_map(), but extends to any list of mirai objects.\nSo no need for any more statements like:\nlapply(list_of_mirai, .subset2, \"data\")\nThis is now a clean, efficient (and faster):\ncollect_mirai(list_of_mirai)\n7. The mirai [] method\nPreviously, collecting the value of a mirai involved a call to call_mirai(), which waits for the mirai to resolve, but then returns the mirai itself. So to access the data at $data requires:\n\n\nm <- mirai(TRUE)\ncall_mirai(m)$data\n\n[1] TRUE\n\nOf course, we also had to remember to use call_mirai_() if we wanted this operation to be user-interruptible.\nNow we recommend the use of x[] which waits for and returns the value of a mirai x directly.\n\n\nm <- mirai(TRUE)\nm[]\n\n[1] TRUE\n\nThis makes the user interface even more minimal. The function mirai() is all that is required. This method is also user-interruptible to avoid any potential surprises.\n8. The with() method for daemons()\nDesigned for a Shiny runApp() call, the with() method can be used to conveniently run any series of mirai calls with daemons settings which are then automatically torn down when they finish.\nThis can help to more clearly define intent within blocks of code. In the Shiny context, it can be confusing where to put the daemons() call in a Shiny app - at the top level or within the server component etc.\nThe recommended Shiny workflow is to first create a Shiny app object, and then run it like so:\napp <- shinyApp(server, ui, session)\nwith(daemons(8), runApp(app))\n9. Error stack traces\nImplementing a request by Joe Cheng, a ‘miraiError’ now returns the stack trace of the daemon process to aid debugging. It is simply available on the ‘miraiError’ object at $stack.trace.\n\n\nm <- mirai({func1 <- function() func2(); func2 <- function() func3(); func1()})\nm[]\n\n'miraiError' chr Error in func3(): could not find function \"func3\"\n\nm$data$stack.trace\n\n[[1]]\n[1] \"function() func2()\"\n\n[[2]]\n[1] \"func1()\"\n\nThis is elegantly implemented behind the scenes using a combination of R’s calling handler and restart system, direct descendants of R’s Common Lisp heritage.\n10. Retry and resilience\nAgain, aiming for behaviour to be less suprising, the built-in automatic retry mechanism in the underlying ‘NNG’ C library is now turned off by default. Disabling features? Well, sometimes ‘less is more’.\nPreviously, for the non-dispatcher case, the retry behaviour was governed by the argument ‘resilience’ at daemons(), with default TRUE. This unfortunately meant that if a piece of buggy code caused a crash, it would be re-tried and crash all connected daemons. This is now disabled for the non-dispatcher case, with the mirai returning an ‘errorValue’ instead.\nWhen using dispatcher, the behaviour is slightly different as the problematic code would be isolated at a particular daemon instance. This provided much more control over how to handle such errors, with the ability to manually cancel such tasks using saisei(). However a ‘retry’ argument has now been added at dispatcher() with a default of FALSE. This is as a mirai could remain unresolved indefinitely if retries are enabled. This is something that is not always obvious to check for, although possible by inspecting status().\nThis behavioural update will be completed with the imminent release of mirai version 1.1.1, closely co-ordinated with updates to crew by Will Landau, a package that extends mirai and integrates it as the high performance computing backend for targets reproducible workflows.\n And that’s it! A whistle-stop tour of lots of different types of improvement. All designed to ensure that mirai remains best in class for everything it does. If you have any comments or suggestions, please post in the issues or discussions at the package repository: https://github.com/shikokuchuo/mirai/\n\n\n\n",
    "preview": "posts/23-mirai-quality-of-life-updates/mirai-quality-of-life-updates_files/figure-html5/index-1.png",
    "last_modified": "2024-06-25T11:19:20+01:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/22-moju-kapu-modular-encapsulation/",
    "title": "Moju-kapu（モジュカプ）Modular Encapsulation",
    "description": "A New Software Design Paradigm",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2024-02-21",
    "categories": [
      "R"
    ],
    "contents": "\n\n\n\nIntroduction\nMoju-kapu （モジュカプ） is shorthand for modular encapsulation （モジュラーカプセル化）.\nIt is a software design paradigm which emphasises the inherent balance in building effective stand-alone tools that together form entire integrated systems. It requires modularity such that each piece of software is self-contained, contributing unique functionality in its own right, but at the same time extensible and readily encapsulated by other systems.\nMoju-kapu is about building out core functionality, and recognising the natural limits of a piece of software such that it does not become monolithic, but harks to the Unix philosophy of doing one thing and doing it well. However it extends this idea with providing interfaces for developers as well as end-users, to enable the software to be easily extended in foreseeable ways.\nA layered engineering approach is advocated, where functionality can be filled at any layer, with interfaces to solutions, existing or future, at others. It does not attempt to simplistically define software as modular tools, nor as empty encompassing frameworks.\nExample\n{mirai} 1 is a package implementing asynchronous evaluation for R 2 – fast parallel code execution and distributed computing. It follows the ‘moju-kapu’ paradigm by creating a tight core proposition, with extensions enabled by a complement of external interfaces.\nModular\nThe package has an inherently modular internal design. The adoption of ‘compute profiles’, allows each to keep its own internal state. In the terminology of the package, it allows different ‘daemons’ settings concurrently, where ‘daemons’ are background processes (local or remote) that accept computations.\nThis internal modularity allows it to scale massively, and fits workflows where certain computations need to be sent to specific workers with special resources such as GPUs or accelerators. It also allows segregating different types of usage such that the user interface may function independently of those created by other packages using {mirai} as a backend (see below).\nThis is functionality that is essential to {mirai} and implemented at its core.\nEncapsulation\nThe package has the following explicit external interfaces:\nuser interface - minimalist consisting mainly of two functions - mirai() and daemons().\ndeveloper interface - functions that provide an interface specfically for extension packages.\n‘parallel’ 3 interface - creates ‘cluster’ objects that provide a backend for the ‘parallel’ base R package.\n‘promises’ 4 interface - provides a method that enables ‘mirai’ to be used as ‘promises’.\nThe last two interfaces are not inherent to the functionality of the package itself, hence would not exist if modularity were the sole design goal. However, they provide the necessary interfaces for mirai to be encapsulated by packages that already provide fundamental building blocks in the R ecosystem. Putting in these interfaces enhances these existing packages by making them more performant, or extending their functionality to distributed computing etc.\nIt allows, for example, {shiny} 5 and {plumber} 6, both promises-powered packages, to easily scale and distribute long-running tasks to servers over the network.\nThe developer interface provides safe and easy (read-only) access to mirai internals (the modular compute profiles) for extension packages that provide alternative launchers of ‘daemon’ processes. This has been designed for use by extension packages, and has notably been used by {crew} 7, the new default for high-performance computing in {targets} 8.\n{crew} extends {mirai} to different computing environments such as traditional clusters or the cloud. It also has functionality for auto-scaling daemons according to demand, which is important due to the potential cost of resources in these high-powered environments. This is a key example of functionality being filled at the most appropriate layer - in this case {crew} where it is most applicable, rather than at {mirai} where it would be an under-utilised feature in the majority of contexts.\nConclusion\nBy adopting ‘moju-kapu’ as its overall design ethos, {mirai} serves a much wider section of the R ecosystem, and is inherently more impactful than it would be solely as a modular ‘tool’.\n\nGao (2024), mirai: Minimalist Async Evaluation Framework for R, https://doi.org/10.5281/zenodo.7912722, https://github.com/shikokuchuo/mirai↩︎\nR Core Team (2023), R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing, Vienna, Austria. https://www.R-project.org/↩︎\nhttps://shikokuchuo.net/mirai/articles/parallel.html↩︎\nhttps://shikokuchuo.net/mirai/articles/promises.html↩︎\nhttps://shikokuchuo.net/mirai/articles/shiny.html↩︎\nhttps://shikokuchuo.net/mirai/articles/plumber.html↩︎\nLandau WM (2023), crew: A Distributed Worker Launcher Framework, https://wlandau.github.io/crew/, https://github.com/wlandau/crew↩︎\nLandau, W. M., (2021), The targets R package: a dynamic Make-like function-oriented pipeline toolkit for reproducibility and high-performance computing. Journal of Open Source Software, 6(57), 2959, https://doi.org/10.21105/joss.02959↩︎\n",
    "preview": "posts/22-moju-kapu-modular-encapsulation/moju-kapu-modular-encapsulation_files/figure-html5/index-1.png",
    "last_modified": "2024-02-22T21:32:53+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 192
  },
  {
    "path": "posts/21-mirai-parallel-clusters/",
    "title": "mirai Parallel Clusters",
    "description": "Making parallel processing work (better) in R",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2024-01-29",
    "categories": [
      "R"
    ],
    "contents": "\nA surprise\nI came to write this post because I was surprised by its findings.\nThe seed for it came from a somewhat obscure source: the Tokyo.R slack channel.\nThis is actually a fairly vibrant R community. In any case, there was a post by an R user suprised to find parallel computation much slower than the sequential alternative - even though he had thousands, tens of thousands of ‘embarassingly parallel’ iterations to compute.\nHe demonstrated this with a simple benchmarking exercise, which showed a variety of parallel map functions from various packages (which shall remain nameless), each slower than the last, and (much) slower than the non-parallel versions.\nThe replies to this post could be anticipated, and mostly aimed to impart some of the received wisdom: namely that you need computations to be sufficiently complex to benefit from parallel processing, due to the extra overhead from sending and coordinating information to and from workers. For simple functions, it is just not worth the effort.\nAnd this is indeed the ‘received wisdom’…\nand I thought about it… and the benchmarking results continued to look really embarassing.\nThe implicit answer was just not particularly satisfying:\n\n‘sometimes it works, you just have to judge when’.\n\nAnd it didn’t really answer the original poster either - for he just attemped to expose the problem by using a simple example, not that his real usage was as simple.\nThe parallel methods just didn’t work. Or rather didn’t ‘just work’TM.\nAnd this is what sparked off The Investigation.\nThe Investigation\nIt didn’t seem right that there should be such a high bar before parallel computations become beneficial in R.\nMy starting point would be mirai, somewhat naturally (as I’m the author). I also knew that mirai would be fast, as it was designed to be minimalist.\nmirai? That’s みらい or Japanese for ‘future’. All you need to know for now is that it’s a package that can create its own special type of parallel clusters.\nI had not done such a benchmarking exercise before as performance itself was not its raison d’être. More than anything else, it was built as a reliable scheduler for distributed computing. It is the engine that powers crew, the high performance computing element of targets, where it is used in industrial-scale reproducible pipelines.\nAnd this is what I found:\nApplying the statistical function rpois() over 10,000 iterations:\n\n\nlibrary(parallel)\nlibrary(mirai)\n\nbase <- parallel::makeCluster(4)\nmirai <- mirai::make_cluster(4)\n\nx <- 1:10000\n\nres <- microbenchmark::microbenchmark(\n  parLapply(base, x, rpois, n = 1),\n  lapply(x, rpois, n = 1),\n  parLapply(mirai, x, rpois, n = 1)\n)\n\nggplot2::autoplot(res) + ggplot2::theme_minimal()\n\n\n\nUsing the ‘mirai’ cluster resulted in faster results than the simple non-parallel lapply(), which was then in turn much faster than the base default parallel cluster.\nFaster!\nI’m only showing the comparison with base R functions. They’re often the most performant after all. The other packages that had featured in the original benchmarking suffer from an even greater overhead than that of base R, so there’s little point showing them above.\nLet’s confirm with an even simpler function…\nApplying the base function sum() over 10,000 iterations:\n\n\nres <- microbenchmark::microbenchmark(\n  parLapply(base, x, sum),\n  lapply(x, sum),\n  parLapply(mirai, x, sum)\n)\n\nggplot2::autoplot(res) + ggplot2::theme_minimal()\n\n\n\nmirai holds its own! Not much faster than sequential, but not slower either.\nBut what if the data being transmitted back and forth is larger, would that make a difference? Well, let’s change up the original rpois() example, but instead of iterating over lamba, have it return increasingly large vectors instead.\nApplying the statistical function rpois() to generate random vectors around length 10,000:\n\n\nx <- 9900:10100\n\nres <- microbenchmark::microbenchmark(\n  parLapplyLB(base, x, rpois, lambda = 1),\n  lapply(x, rpois, lambda = 1),\n  parLapplyLB(mirai, x, rpois, lambda = 1)\n)\n\nggplot2::autoplot(res) + ggplot2::theme_minimal()\n\n\n\nThe advantage is maintained! 1\nSo ultimately, what does this all mean?\nWell, quite significantly, that virtually any place you have ‘embarassingly parallel’ code where you would use lapply() or purrr::map(), you can now confidently replace with a parallel parLapply() using a ‘mirai’ cluster.\nThe answer is no longer ‘sometimes it works, you just have to judge when’, but:\n\n‘yes, it works!’.\n\nWhat is this Magic\nmirai uses the latest NNG (Nanomsg Next Generation) technology, a lightweight messaging library and concurrency framework\n2 - which means that the communications layer is so fast that this no longer creates a bottleneck.\nThe package leverages new connection types such as IPC (inter-process communications), that are not available to base R. As part of R Project Sprint 2023, R Core invited participants to provide alternative commnunications backends for the parallel package, and ‘mirai’ clusters were born as a result.\nA ‘mirai’ cluster is simply another type of ‘parallel’ cluster, and are persistent background processes utilising cores on your own machine, or on other machines across the network (HPCs or even the cloud).\nI’ll leave it here for this post. You’re welcome to give mirai a try, it’s available on CRAN and at https://github.com/shikokuchuo/mirai.\n\nThe load-balanced version parLapplyLB() is used to show that this variant works equally well.↩︎\nThrough the nanonext package, a high-performance R binding.↩︎\n",
    "preview": "posts/21-mirai-parallel-clusters/mirai-parallel-clusters_files/figure-html5/rpois-1.png",
    "last_modified": "2024-01-29T11:54:23+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/20-ncurl-sessions/",
    "title": "nanonext - High Performance Persistent HTTP Sessions",
    "description": "ncurl sessions",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2023-01-26",
    "categories": [
      "R"
    ],
    "contents": "\n\nContents\nncurl_session()\ntransact()\nTiming\nLinks\n\n\n\n\n\nShikokuchuo\n\nPersistent http(s) sessions is a new feature added in nanonext 0.7.3.\nThis allows for efficient polling by keeping an open connection with the server, transacting as and when needed.\nProvides an ideal, low-latency solution to requesting real time data over a REST API, especially when there are limits in place for the frequency of new connections.\nncurl_session()\nCreate a session (persistent connection):\n\n\nlibrary(nanonext)\nsess <- ncurl_session(\"https://httpbin.org/headers\")\n\n\ntransact()\nTransact over the session (repeatedly if required):\n\n\nres <- transact(sess)\nres\n\n$status\n[1] 200\n\n$headers\nNULL\n\n$raw\n  [1] 7b 0a 20 20 22 68 65 61 64 65 72 73 22 3a 20 7b 0a 20 20 20 20\n [22] 22 48 6f 73 74 22 3a 20 22 68 74 74 70 62 69 6e 2e 6f 72 67 22\n [43] 2c 20 0a 20 20 20 20 22 58 2d 41 6d 7a 6e 2d 54 72 61 63 65 2d\n [64] 49 64 22 3a 20 22 52 6f 6f 74 3d 31 2d 36 33 64 32 64 64 38 63\n [85] 2d 32 61 66 61 34 64 65 33 32 37 34 35 36 62 30 34 30 33 35 34\n[106] 34 63 33 39 22 0a 20 20 7d 0a 7d 0a\n\n$data\n[1] \"{\\n  \\\"headers\\\": {\\n    \\\"Host\\\": \\\"httpbin.org\\\", \\n    \\\"X-Amzn-Trace-Id\\\": \\\"Root=1-63d2dd8c-2afa4de327456b0403544c39\\\"\\n  }\\n}\\n\"\n\nTiming\nAllows much lower latencies in returning results:\n\n\nlibrary(microbenchmark)\n\nmicrobenchmark(transact(sess), ncurl(\"https://httpbin.org/headers\"))\n\nUnit: milliseconds\n                                 expr       min        lq     mean\n                       transact(sess)  78.14837  82.39269 160.0736\n ncurl(\"https://httpbin.org/headers\") 474.78558 488.71817 793.1671\n    median       uq        max neval\n  84.85723 140.6003   784.5898   100\n 498.19017 516.3694 15475.3540   100\n\nLinks\n{nanonext} package website: https://shikokuchuo.net/nanonext/\nOn CRAN: https://cran.r-project.org/package=nanonext\n{nanonext} features in the ‘Web Technologies’ CRAN Task View under ‘Core Tools For HTTP Requests’: https://cran.r-project.org/view=WebTechnologies\nand also in the ‘High Performance Computing’ CRAN Task View:\nhttps://cran.r-project.org/view=HighPerformanceComputing\n\n\n\n",
    "preview": "posts/20-ncurl-sessions/ncurl-sessions_files/figure-html5/index-1.png",
    "last_modified": "2023-01-26T20:10:34+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/19-nanonext-webtools/",
    "title": "nanonext - a web toolkit",
    "description": "async https and secure websocket client and cryptographic hashing",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2022-09-08",
    "categories": [
      "R"
    ],
    "contents": "\n\nContents\nncurl - a minimalist (async) http(s) client\nstream - websocket client\nsha[224|256|384|512] - cryptographic hash and HMAC algorithms\nmessenger - console-based instant messaging\n\n\n\n\n\nShikokuchuo\n\nThe previous two articles have centered on the main uses which led to the creation of Nanonext - the desire to bridge code written in different languages, as well as the ability to perform actions concurrently.\nThis article aims to highlight the additional features that have been built around the core capabilities in the NNG library that actually make it a very good tool for interacting with the web.\nThis is especially relevant as version 0.5.5 just released to CRAN integrates the ‘mbedtls’ library providing TLS support for secure websites and websocket connections across all platforms.\nThe package has also made it into the ‘Web Technologies’ CRAN Task View under ‘Core Tools For HTTP Requests’: https://cran.r-project.org/view=WebTechnologies\n\n\nlibrary(nanonext)\n\n\nncurl - a minimalist (async) http(s) client\nFor normal use, it takes just the URL.\nIt can follow redirects.\n\n\nncurl(\"https://httpbin.org/headers\")\n\n$status\n[1] 200\n\n$headers\nNULL\n\n$raw\n  [1] 7b 0a 20 20 22 68 65 61 64 65 72 73 22 3a 20 7b 0a 20 20 20 20\n [22] 22 48 6f 73 74 22 3a 20 22 68 74 74 70 62 69 6e 2e 6f 72 67 22\n [43] 2c 20 0a 20 20 20 20 22 58 2d 41 6d 7a 6e 2d 54 72 61 63 65 2d\n [64] 49 64 22 3a 20 22 52 6f 6f 74 3d 31 2d 36 33 64 32 64 65 61 31\n [85] 2d 32 64 66 34 30 61 36 34 30 35 33 33 64 33 34 65 30 34 39 64\n[106] 37 61 30 63 22 0a 20 20 7d 0a 7d 0a\n\n$data\n[1] \"{\\n  \\\"headers\\\": {\\n    \\\"Host\\\": \\\"httpbin.org\\\", \\n    \\\"X-Amzn-Trace-Id\\\": \\\"Root=1-63d2dea1-2df40a640533d34e049d7a0c\\\"\\n  }\\n}\\n\"\n\nWhilst it is designed to be minimalist and easy to use, the real power however lies in its ability to use other methods such as POST or PUT, and the ability of the arguments ‘headers’ and ‘data’ to take arbitrary values that are sent in the HTTP request.\nThis makes it perfect as a client for making REST API calls, and is indeed a rather performant solution.\n\n\nres <- ncurl(\"http://httpbin.org/post\",\n             async = TRUE,\n             convert = FALSE,\n             method = \"POST\",\n             headers = c(`Content-Type` = \"application/json\", Authorization = \"Bearer APIKEY\"),\n             data = '{\"key\": \"value\"}',\n             response = c(\"Date\", \"Server\"))\n\n\nAbove:\n‘async’ is set to TRUE to return an ‘ncurlAio’ object immediately, with the request happening asynchronously. The data will be available once resolved, or if called explicitly (which will wait).\n‘convert’ is set to FALSE so time is not wasted converting the raw data to characters, which is useful when, for example, a JSON parser can directly parse the raw bytes.\n‘response’ is specified to return the requested response headers.\n\n\nres\n\n< ncurlAio >\n - $status for response status code\n - $headers for response headers\n - $raw for raw message\n - $data for message data\n\ncall_aio(res)$status\n\n[1] 200\n\nres$headers\n\n$Date\n[1] \"Thu, 26 Jan 2023 20:12:17 GMT\"\n\n$Server\n[1] \"gunicorn/19.9.0\"\n\nres$raw\n\n  [1] 7b 0a 20 20 22 61 72 67 73 22 3a 20 7b 7d 2c 20 0a 20 20 22 64\n [22] 61 74 61 22 3a 20 22 7b 5c 22 6b 65 79 5c 22 3a 20 5c 22 76 61\n [43] 6c 75 65 5c 22 7d 22 2c 20 0a 20 20 22 66 69 6c 65 73 22 3a 20\n [64] 7b 7d 2c 20 0a 20 20 22 66 6f 72 6d 22 3a 20 7b 7d 2c 20 0a 20\n [85] 20 22 68 65 61 64 65 72 73 22 3a 20 7b 0a 20 20 20 20 22 41 75\n[106] 74 68 6f 72 69 7a 61 74 69 6f 6e 22 3a 20 22 42 65 61 72 65 72\n[127] 20 41 50 49 4b 45 59 22 2c 20 0a 20 20 20 20 22 43 6f 6e 74 65\n[148] 6e 74 2d 4c 65 6e 67 74 68 22 3a 20 22 31 36 22 2c 20 0a 20 20\n[169] 20 20 22 43 6f 6e 74 65 6e 74 2d 54 79 70 65 22 3a 20 22 61 70\n[190] 70 6c 69 63 61 74 69 6f 6e 2f 6a 73 6f 6e 22 2c 20 0a 20 20 20\n[211] 20 22 48 6f 73 74 22 3a 20 22 68 74 74 70 62 69 6e 2e 6f 72 67\n[232] 22 2c 20 0a 20 20 20 20 22 58 2d 41 6d 7a 6e 2d 54 72 61 63 65\n[253] 2d 49 64 22 3a 20 22 52 6f 6f 74 3d 31 2d 36 33 64 32 64 65 61\n[274] 31 2d 35 66 62 35 36 64 66 38 31 61 31 65 30 33 64 32 31 32 61\n[295] 32 35 33 34 64 22 0a 20 20 7d 2c 20 0a 20 20 22 6a 73 6f 6e 22\n[316] 3a 20 7b 0a 20 20 20 20 22 6b 65 79 22 3a 20 22 76 61 6c 75 65\n[337] 22 0a 20 20 7d 2c 20 0a 20 20 22 6f 72 69 67 69 6e 22 3a 20 22\n[358] 31 38 35 2e 32 32 35 2e 34 35 2e 34 39 22 2c 20 0a 20 20 22 75\n[379] 72 6c 22 3a 20 22 68 74 74 70 3a 2f 2f 68 74 74 70 62 69 6e 2e\n[400] 6f 72 67 2f 70 6f 73 74 22 0a 7d 0a\n\nThe function is named ‘ncurl’ after the ubiquitous ‘curl’, but it uses a completely different technology stack, leveraging the ‘NNG’ and ‘MbedTLS’ libraries instead.\nstream - websocket client\nstream() exposes NNG’s low-level byte stream interface for communicating with raw sockets. This may be used for connecting to arbitrary non-NNG endpoints.\nPerhaps its most important use (in connection with the web at least), is for communicating with (secure) websocket servers. The argument textframes = TRUE can be specified where the websocket server uses text rather than binary frames, which is often the case.\n\n\n# official demo API key used below\ns <- stream(dial = \"wss://ws.eodhistoricaldata.com/ws/forex?api_token=OeAFFmMliFG5orCUuwAKQ8l4WWFQ67YX\",\n            textframes = TRUE)\ns\n\n< nanoStream >\n - type: dialer\n - url: wss://ws.eodhistoricaldata.com/ws/forex?api_token=OeAFFmMliFG5orCUuwAKQ8l4WWFQ67YX\n - textframes: TRUE\n\nsend() and recv(), as well as their asynchronous counterparts send_aio() and recv_aio() can be used on Streams in the same way as Sockets.\nThis affords a great deal of flexibility in ingesting, manipulating and processing streaming data.\n\n\ns |> recv(keep.raw = FALSE)\n\n[1] \"{\\\"status_code\\\":200,\\\"message\\\":\\\"Authorized\\\"}\"\n\ns |> send('{\"action\": \"subscribe\", \"symbols\": \"EURUSD\"}')\n\n[1] 0\n\ns |> recv(keep.raw = FALSE)\n\n[1] \"{\\\"s\\\":\\\"EURUSD\\\",\\\"a\\\":1.08901,\\\"b\\\":1.08894,\\\"dc\\\":\\\"-0.2792\\\",\\\"dd\\\":\\\"-0.0030\\\",\\\"ppms\\\":false,\\\"t\\\":1674763938000}\"\n\ns |> recv(keep.raw = FALSE)\n\n[1] \"{\\\"s\\\":\\\"EURUSD\\\",\\\"a\\\":1.08901,\\\"b\\\":1.08899,\\\"dc\\\":\\\"-0.2792\\\",\\\"dd\\\":\\\"-0.0030\\\",\\\"ppms\\\":false,\\\"t\\\":1674763938000}\"\n\nclose(s)\n\n\nsha[224|256|384|512] - cryptographic hash and HMAC algorithms\nAs ‘nanonext’ now links to the ‘mbedtls’ library as well as ‘NNG’, the series of SHA-2 crypographic hash functions have been added to the package: sha224(), sha256(), sha384() and sha512().\nThese call the secure, optimized implementations from the ‘MbedTLS’ library and return a hash as a raw vector. These can be compared directly for authentication. Alternatively, as.character() may be used to return a character string of the hash value.\nTo generate an HMAC (hash-based message authentication code), simply supply the value ‘key’ to use as the secret key. Many REST APIs require the request strings to be signed, and now the ‘nanonext’ package provides a fast and reliable method of generating a SHA-256 HMAC for this purpose.\n\n\nsha256(\"hello world!\")\n\n[1] \"7509e5bda0c762d2bac7f90d758b5b2263fa01ccbc542ab5e3df163be08e6ca9\"\n\nas.character(sha256(\"hello world!\"))\n\n[1] \"7509e5bda0c762d2bac7f90d758b5b2263fa01ccbc542ab5e3df163be08e6ca9\"\n\nsha256(\"hello world!\", key = \"MY_SECRET\")\n\n[1] \"d8f0e2d368ff632682d55e2c1ccd49c15f8a6a3862d8eb68f1906b6ee658890a\"\n\nmessenger - console-based instant messaging\nThere is also messenger() which is not so easy to demonstrate here as it is by nature interactive, but it is in effect a 2-way walkie talkie which can be connected to a TCP/IP or other socket address. This is a rather fun demonstration of how a multi-threaded application can be built using the NNG framework.\nWhilst this function has been around for quite a few versions of ‘nanonext’, the recent addition of authentication based on a pre-shared key makes it a somewhat viable solution rather than just something for fun. We encourage you to give it a try and play around with it.\n\n\n?messenger\n\n\nPackage website: https://shikokuchuo.net/nanonext/\nOn CRAN: https://cran.r-project.org/package=nanonext\n\n\n\n",
    "preview": "posts/19-nanonext-webtools/nanonext-webtools_files/figure-html5/index-1.png",
    "last_modified": "2023-01-26T20:13:38+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/18-reintroducing-mirai/",
    "title": "Re-introducing mirai - a minimalist async evaluation framework for R",
    "description": "Concurrent code execution with maximum flexibility and automatic resolution",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2022-04-18",
    "categories": [
      "R"
    ],
    "contents": "\n\nContents\n1. Two Functions -> One\nFunction\n2. Automatic Resolution\n3. Arbitrary expressions\n4. Daemons\nWrap-up\n\n\n\n\n\nShikokuchuo\n {mirai} is a minimalist async evaluation framework for R.\n未来 みらい mirai is Japanese for ‘future’.\nmirai provides\nan extremely simple and lightweight method for concurrent / parallel\ncode execution.\nSince the original ‘introduction’\narticle two months ago, mirai is currently in its fourth\nincarnation, hence the need for a re-introduction. In this time, the\npackage has also featured in RStudio’s Top\n40 New CRAN Packages for February 2022.\nWe outline some of the main visible innovations below, but suffice to\nsay that the backend (especially the code behind the nanonext package)\nhas been very much optimised over the course of this time as well.\n1. Two Functions -> One\nFunction\nOriginally, the package revolved around 2 functions -\neval_mirai() and call_mirai(). Those are still\nthere, and work the same way - however the package has managed to become\neven more minimalist with only one being required now.\nThis one function is simply called mirai().\n(eval_mirai() maps to it as an alias.)\nUsing mirai() returns a ‘mirai’ object immediately.\nA mirai evaluates an arbitrary expression asynchronously, resolving\nautomatically upon completion.\n2. Automatic Resolution\nYes, resolving automatically, hence call_mirai() is no\nlonger needed (although it can still sometimes be useful to call and\nwait for results).\nThe evaluated result of a mirai is stored at $data. If\nthe asynchronous operation has yet to complete then this will return an\n‘unresolved’ logical NA value. That is an actual NA value of type\nlogical classed as ‘unresolved’.\nAs soon as it resolves, then $data will return the\nactual value of the evaluated expression.\nEnter unresolved(), a helper function that can be used\nin control flow statements to allow you to do things before and after\nresolution of a mirai. This means that you never have to actually just\nwait on a mirai.\nThe code output below probably serves as a better demonstration than\na lengthy explanation:\nExample using a while loop:\n\n\nlibrary(mirai)\n\nm <- mirai({is.null(Sys.sleep(n)) && return(TRUE)}, n = 1)\nm$data\n\n\n'unresolved' logi NA\n\nwhile (unresolved(m)) {\n  cat(\"unresolved\\n\")\n  Sys.sleep(1)\n} \n\n\nunresolved\nunresolved\n\nm$data\n\n\n[1] TRUE\n\nEquivalent using a repeat\nloop:\n\n\nm <- mirai({is.null(Sys.sleep(n)) && return(TRUE)}, n = 1)\nm$data\n\n\n'unresolved' logi NA\n\nrepeat {\n  unresolved(m) || break\n  cat(\"unresolved\\n\")\n  Sys.sleep(1)\n} \n\n\nunresolved\nunresolved\n\nm$data\n\n\n[1] TRUE\n\n3. Arbitrary expressions\nYou may have noticed in the above examples that the expression being\nevaluated was wrapped in { }. mirai supports this being an\narbitrarily-long, possibly multi-line expression. Similarly there is no\nlimit to the number of arguments supplied to the call.\nTo supply objects that are already present in the calling\nenvironment, these may simply be passed in as per the below:\n\n\nmat <- matrix(c(1, 2, 3, 4), ncol = 2)\nmat\n\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\nm <- mirai({\n  x <- t(x)\n  as.data.frame(x)\n}, x = mat)\n\ncall_mirai(m)$data\n\n\n  V1 V2\n1  1  2\n2  3  4\n\n4. Daemons\nThe default behaviour is to just spin up background processes as\nrequired. This offers maximum simplicity and ease of use - no need to\nconsider the backend at all.\nFirst of all this is remarkable in itself, in that mirai simply works\non all platforms R can be installed - across Linux, Windows, Mac,\nSolaris etc. and this is down to the cross-platform support built in to\nthe underlying NNG C library that nanonext provides\na binding for.\nSecond, the startup time is relatively tiny as a completely clean\nbackground R process with ‘–vanilla’ settings is started each time.\nHowever for the highest performance applications, there is now the\noption to start up a set number of processes (daemons) upfront, and\nthese will be ready to wait for instructions, achieveing even more\nminimal latency.\nSetting daemons is as simple as:\n\n\ndaemons(8)\n#> [1] 8\n\n\n\n.. and 8 daemons are created.\nWrap-up\nWe presented above 4 key updates for the fourth version of mirai (v0.4.0). We\ninvite you to try it out for yourselves:\n\n\ninstall.packages(\"mirai\")\n\n\n\nAny issues/comments please feed back at Github: https://github.com/shikokuchuo/mirai\nPackage website: https://shikokuchuo.net/mirai/\n\n\n\n",
    "preview": "posts/18-reintroducing-mirai/reintroducing-mirai_files/figure-html5/index-1.png",
    "last_modified": "2022-04-18T11:06:03+01:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/17-nanonext-concurrency/",
    "title": "nanonext - how it provides a concurrency framework for R",
    "description": "True async with automatic resolution",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2022-03-18",
    "categories": [
      "R"
    ],
    "contents": "\n\nContents\nAios\nRPC\nmirai\n\n\n\n\n\nShikokuchuo\nThe nanonext package,\nfeatured in RStudio’s Top\n40 New CRAN Packages for January 2022 has been steadily evolving,\nadding significant new features, with the aysnc ‘Aio’ interface now\nconsidered complete since release 0.3.0 hit CRAN earlier in March.\nHence, time to introduce why this is a ‘concurrency framework’ and\nnot ‘just’ messaging.\nnanonext is\na lightweight binding for the NNG (nanomsg next gen) C library, written\nin a combination of R and C with no package dependencies. For the\nexperts who need no further introduction, they may wish to skip straight\nto the pkgdown site which contains a more systematic exposition of the\nfeatures: https://shikokuchuo.net/nanonext/.\nAios\nThese are self-resolving objects containing the results of an async\noperation.\nThe purpose of this section is really to highlight that this is true\nasync - the real thing. No event loops, nor any other similar\nconstraints. This provides the freedom to be much more expressive when\ncoding. Below, we perform actions out of order - receive before we send\n- and it is all totally fine.\n\n\n# loading the package and creating sockets\nlibrary(nanonext)\ns1 <- socket(\"pair\", listen = \"inproc://nano\")\ns2 <- socket(\"pair\", dial = \"inproc://nano\")\n\n# an async receive is requested, but no messages are waiting (yet to be sent)\nmsg <- s2 |> recv_aio()\nmsg\n\n\n< recvAio >\n - $data for message data\n - $raw for raw message\n\nmsg$data\n\n\n'unresolved' logi NA\n\nsend_aio() and recv_aio() functions return\nimmediately with an ‘Aio’ object, but perform their operations async. An\n‘Aio’ object returns an ‘unresolved’ logical NA value whilst its\nasynchronous operation is ongoing. This is an actual NA value, and Shiny\nwill, for example, recognise it as being ‘non-truthy’.\nNext we perform a send, and the ‘Aio’ resolves immediately once we do\nthat. 1\n\n\nres <- s1 |> send_aio(data.frame(a = 1, b = 2))\n\n# now that a message has been sent, the 'recvAio' automatically resolves\nmsg$data\n\n\n  a b\n1 1 2\n\nmsg$raw\n\n\n  [1] 58 0a 00 00 00 03 00 04 01 03 00 03 05 00 00 00 00 05 55 54 46\n [22] 2d 38 00 00 03 13 00 00 00 02 00 00 00 0e 00 00 00 01 3f f0 00\n [43] 00 00 00 00 00 00 00 00 0e 00 00 00 01 40 00 00 00 00 00 00 00\n [64] 00 00 04 02 00 00 00 01 00 04 00 09 00 00 00 05 6e 61 6d 65 73\n [85] 00 00 00 10 00 00 00 02 00 04 00 09 00 00 00 01 61 00 04 00 09\n[106] 00 00 00 01 62 00 00 04 02 00 00 00 01 00 04 00 09 00 00 00 05\n[127] 63 6c 61 73 73 00 00 00 10 00 00 00 01 00 04 00 09 00 00 00 0a\n[148] 64 61 74 61 2e 66 72 61 6d 65 00 00 04 02 00 00 00 01 00 04 00\n[169] 09 00 00 00 09 72 6f 77 2e 6e 61 6d 65 73 00 00 00 0d 00 00 00\n[190] 02 80 00 00 00 ff ff ff ff 00 00 00 fe\n\nSo isn’t this still ‘just’ messaging?\nWell, we can start with introducing a little helper function\nunresolved(). This allows us to perform actions which\ndepend on resolution of the Aio (completion of the async operation),\nboth before and after. This means there is no need to ever wait (block)\nfor an Aio to resolve, as the below demonstrates:\n\n\nmsg <- recv_aio(s2)\n\n# unresolved() queries for resolution itself so no need to use it again within the while loop\nwhile (unresolved(msg)) {\n  # do real stuff here not just the toy actions below\n  cat(\"unresolved\")\n  send_aio(s1, \"resolved\")\n  Sys.sleep(0.1)  \n}\n\n\nunresolved\n\n# resolution of the Aio exits the while loop - now do the stuff which depends on its value\nmsg$data\n\n\n[1] \"resolved\"\n\nAlternatively, an Aio may also be called explicitly by wrapping it in\ncall_aio(). This will wait for completion of the Aio\n(blocking) if it is yet to resolve.\n\n\n# to access the resolved value directly (waiting if required)\ncall_aio(msg)$data\n\n\n[1] \"resolved\"\n\nThe above two methods provide full flexibility for handling async\noperations as desired.\n\n\n\nRPC\nSo we move closer to explaining how this is a ‘concurrency\nframework’. And this involves explaining a little about NNG’s\n‘scalability protocols’ - so-called as they are designed to be\nmasssively scalable.\nThese can be thought of as communications patterns built on top of\nraw bytestream connections. So a socket of a certain type will always\ninteract with another in a prescribed way. No matter the platform, and\nno matter the language binding.\nProbably the most classic pattern for NNG is the req/rep\n(request/reply). This is a guaranteed communications pattern that will\nnot drop messages, retrying under the hood if messages cannot be\ndelivered for whatever reason. This can be utilised to implement\n‘traditional’ RPC (remote prodecure calls), a bastion of\nsystems/distributed computing. 2\nThis is where a requestor (client) sends a message to an executor\n(server), which performs the requested action and sends back a reply.\n{nanonext} provides the convenience functions request() and\nreply() which implements this logic for use between 2 R\nprocesses, where the requestor supplies data to the reply node, to which\nit applies an arbitrary function before sending back the return\nvalue.\nThis can be meaningfully used to perform computationally-expensive\ncalculations or I/O-bound operations such as writing large amounts of\ndata to disk in a separate ‘server’ process running concurrently.\nServer process: reply() will wait for a message and\napply a function, in this case rnorm(), before sending back\nthe result.\n\n\n# This code block is run in a separate R process to knit this document\n\nlibrary(nanonext)\nrep <- socket(\"rep\", listen = \"tcp://127.0.0.1:6546\")\nctxp <- context(rep)\nreply(ctxp, execute = rnorm, send_mode = \"raw\") \n\n\n\nClient process: request() performs an async send and\nreceive request and returns immediately with an Aio object.\n\n\nlibrary(nanonext)\nreq <- socket(\"req\", dial = \"tcp://127.0.0.1:6546\")\nctxq <- context(req)\naio <- request(ctxq, data = 1e8, recv_mode = \"double\", keep.raw = FALSE)\n\n\n\nAt this point, the client can run additional code concurrent with the\nserver processing the request. The Aio will then resolve automatically\nor can be called as required.\n\n\ncall_aio(aio)$data |> str()\n\n\n num [1:100000000] 1.633 -0.204 -0.521 0.19 0.373 ...\n\nAnd this is how nanonext provides\na true concurrency framework. The package provides the necessary tools\nto implement anything from a walkie-talkie to distributed computing\nclusters and everything in between.\nmirai\nA small (tiny) package has also been released to CRAN in February\n2022 that exposes the functionality of executing arbitrary R expressions\nasynchronously for use on a single machine. It is called ‘mirai’, the Japanese\nfor ‘future’. Everything revolves around one single function. It is very\nminimalistic. Designed to be intuitive to use, a short intro can be\nfound here: https://shikokuchuo.net/mirai/.\n\nOr more precisely, the Aio will\nresolve the next time it is queried - but practically this is the same\nthing, as the value cannot be used unless it is queried. This is akin to\n‘Schrödinger’s Cat’ - if we never look into the box, we simply don’t\nknow the state, but as soon as we look, we will get a resolution one way\nor another. Here, if the value is never used, it could remain in a state\nof ‘superposition’ but as soon as it is required (even if we are only\nseeking metadata such as its length rather than the actual value), it\nwill resolve either to an ‘unresolved’ NA or its actual value.↩︎\nAlthough the generic term includes\n‘remote’, obviously everything can also happen on the same machine in\nseparate processes.↩︎\n",
    "preview": "posts/17-nanonext-concurrency/nanonext-concurrency_files/figure-html5/index-1.png",
    "last_modified": "2022-03-18T12:18:39+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/16-introducing-mirai/",
    "title": "Introducing mirai - a minimalist async evaluation framework for R",
    "description": "Concurrency and parallel code execution",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2022-02-18",
    "categories": [
      "R"
    ],
    "contents": "\n\nContents\nDesign Notes\nUse Cases\nLinks\nUpdate\n\n\n\n\n\nShikokuchuo\n {mirai} is a minimalist async evaluation framework for R,\nreleased this week to CRAN.\n未来 みらい mirai is Japanese for ‘future’.\nIt provides an extremely simple and lightweight method for concurrent\n/ parallel code execution.\nDesign Notes\nWhilst frameworks for parallelisation exist for R, {mirai} is\ndesigned for simplicity.\nThe package provides just 2 functions:\neval_mirai() to evaluate async\ncall_mirai() to call the result\n{mirai} has a tiny pure R code base, relying on a single package -\n{nanonext}. {nanonext} itself is a lightweight wrapper for the NNG C\nlibrary with zero package dependencies.\nBackground R processes are created and evaluation occurs\nindependently. mirai employs nanonext/NNG as a concurrency framework - a\nblazing-fast, lightweight solution for moving data between these\nprocesses seamlessly. Crucially it provides a true cross-platform\nabstraction layer across Linux, Windows, MacOS, the BSDs, Solaris,\nIllumos etc. i.e. everywhere R can go. This means that we can just call\nthe above two functions without worrying about the underlying system\nimplementation.\nThis means there is no need to specify core counts, devise work plans\nand the such beforehand. Also no need to separate writing code that is\nready for parallel execution from how it is ultimately executed. Just\nwrap your expressions in eval_mirai() and run them in\nanother process.\nFor scripts, this provides the ultimate control as you can map\nspecific code to a specific process. For example if you have 8 model\nfits to run, you can send each one to it’s own process. This provides a\nsimpler and more robust solution than leaving it to the system to\ndecide, which also runs the risk of over-optimisation - you may wish to\nrefer to this classic presentation on Python’s GIL (global interpreter\nlock): http://www.dabeaz.com/python/GIL.pdf. R inherits similar\nlimitations being an interpreted language.\nIt can be equally handy for interactive work - if you have specified\na model, are now ready to fit it and know this will take an hour to run,\nsimply eval_mirai() and have it run in the background\nwhilst you continue with your work. When you need the results just\ncall_mirai() for the return value.\nUse Cases\nMinimise execution times by performing long-running tasks\nconcurrently in separate processes.\nEnsure execution flow of the main process is not blocked.\n\n\nlibrary(mirai)\n\n\n\nExample 1:\nCompute-intensive Operations\nMultiple long computes (model fits etc.) would take more time than if\nperformed concurrently on available computing cores.\nUse eval_mirai() to evaluate an expression in a separate\nR process asynchronously.\nAll named objects are passed through to a clean environment\nA ‘mirai’ object is returned immediately.\n\n\nmirai <- eval_mirai(rnorm(n) + m, n = 1e8, m = runif(1))\n\nmirai\n#> < mirai >\n#>  ~ use call_mirai() to resolve\n\n\n\nContinue running code concurrent to the async operation.\n\n\n# do more...\n\n\n\nUse call_mirai() to retrieve the evaluated result when\nrequired.\n\n\ncall_mirai(mirai)\n\nmirai\n#> < mirai >\n#>  - $value for evaluated result\n\nstr(mirai$value)\n#> num [1:100000000] 1.485 -0.804 0.965 -0.128 -0.555 ...\n\n\n\nExample 2: I/O-bound\nOperations\nProcessing high-frequency real-time data, writing results to\nfile/database can be slow and potentially disrupt the execution\nflow.\nCache data in memory and use eval_mirai() to perform\nperiodic write operations in a separate process.\nA ‘mirai’ object is returned immediately.\n\n\nmirai <- eval_mirai(write.csv(x, file = file), x = rnorm(1e8), file = tempfile())\n\n\n\nUse call_mirai() to confirm the operation has\ncompleted.\nThis will wait for the operation to complete if it is still\nongoing\n\n\ncall_mirai(mirai)$value\n#> NULL\n\n\n\nAbove, the return value is called directly. NULL is the expected\nreturn value for write.csv().\nLinks\n{mirai} website: https://shikokuchuo.net/mirai/ {mirai} on CRAN: https://cran.r-project.org/package=mirai\n{nanonext} website: https://shikokuchuo.net/nanonext/ {nanonext} on\nCRAN: https://cran.r-project.org/package=nanonext\nUpdate\nThe following article provides an update: re-introducting\nmirai\n\n\n\n",
    "preview": "posts/16-introducing-mirai/introducing-mirai_files/figure-html5/index-1.png",
    "last_modified": "2022-04-18T10:56:35+01:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/15-nanonext-exchange/",
    "title": "nanonext for Cross-language Data Exchange",
    "description": "A clean and robust approach to R / Python interoperability",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2022-02-14",
    "categories": [
      "R"
    ],
    "contents": "\n\nContents\nLinks\n\n\n\n\n\nShikokuchuo\n{nanonext} is an R package available on CRAN which provides bindings to the C library NNG (Nanomsg Next Gen), a successor to ZeroMQ.\nDesigned for performance and reliability, the NNG library is written in C and {nanonext} is a lightweight wrapper depending on no other packages.\nIt provides a fast and reliable data interface between different programming languages where NNG has a binding, including C, C++, Java, Python, Go, Rust etc.\nThe following example demonstrates the exchange of numerical data between R and Python (NumPy), two of the most commonly-used languages for data science and machine learning.\nUsing a messaging interface provides a clean and robust approach that is light on resources and offers limited and identifiable points of failure. This is especially relevant when processing real-time data, as an example.\nThis approach can also serve as an interface / pipe between different processes written in the same or different languages, running on the same computer or distributed across networks, and is an enabler of modular software design as espoused by the Unix philosophy.\nCreate socket in Python using the NNG binding ‘pynng’:\n\nimport numpy as np\nimport pynng\nsocket = pynng.Pair0(listen=\"ipc:///tmp/nanonext\")\n\nCreate nano object in R using {nanonext}, then send a vector of ‘doubles’, specifying mode as ‘raw’:\n\n\nlibrary(nanonext)\nn <- nano(\"pair\", dial = \"ipc:///tmp/nanonext\")\nn$send(c(1.1, 2.2, 3.3, 4.4, 5.5), mode = \"raw\")\n#>  [1] 9a 99 99 99 99 99 f1 3f 9a 99 99 99 99 99 01 40 66 66 66 66 66 66 0a 40 9a\n#> [26] 99 99 99 99 99 11 40 00 00 00 00 00 00 16 40\n\n\n\nReceive in Python as a NumPy array of ‘floats’, and send back to R:\n\nraw = socket.recv()\narray = np.frombuffer(raw)\nprint(array)\n#> [1.1 2.2 3.3 4.4 5.5]\nmsg = array.tobytes()\nsocket.send(msg)\n\nReceive in R, specifying the receive mode as ‘double’:\n\n\nn$recv(mode = \"double\")\n#> $raw\n#>  [1] 9a 99 99 99 99 99 f1 3f 9a 99 99 99 99 99 01 40 66 66 66 66 66 66 0a 40 9a\n#> [26] 99 99 99 99 99 11 40 00 00 00 00 00 00 16 40\n#> \n#> $data\n#> [1] 1.1 2.2 3.3 4.4 5.5\n\n\n\nLinks\nnanonext on CRAN: https://cran.r-project.org/package=nanonext Package website: https://shikokuchuo.net/nanonext/\nNNG website: https://nng.nanomsg.org/ NNG documentation: https://nng.nanomsg.org/man/tip/\n\n\n\n",
    "preview": "posts/15-nanonext-exchange/nanonext-exchange_files/figure-html5/index-1.png",
    "last_modified": "2022-02-15T14:44:45+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/14-r-on-solaris/",
    "title": "Installing an R Build Environment on Solaris",
    "description": "Run R CMD check or devtools::check() on a local Solaris VM",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2021-08-23",
    "categories": [
      "R"
    ],
    "contents": "\n\nContents\nSetup\nBonus\nPower off\n\n\n\n\n\nShikokuchuo\nSetup\nThe R-hub solarischeck repository1, provides a full set of instructions by Gábor Csárdi for setting up R on a Solaris system. However, due to the ever-evolving software landscape, the instructions as they stand are no longer likely to produce a working system.\nThis guide builds on and completes the set of instructions so that a full build system can be set up with relative ease, complete with ‘devtools’ installed and ready for package testing on a CRAN-like Solaris environment.\nWhere ‘Instructions’ are mentioned below, they refer to those found at the original solarischeck repository:\nhttps://github.com/r-hub/solarischeck/tree/master/packer.\n[1]\nFollow steps 1-3 of the Instructions, including installing the latest Packer version from its website. The website provides clear guidance on the best installation method - for example, for Ubuntu Linux users, a PPA is provided for a straightforward install process.\n[2]\nFollow step 4 of the Instructions and edit ‘solaris10.json’ to point to the locations of the downloaded Solaris 10 iso and Oracle Developer Studio tar.bz2.\nIn addition, find the following line in ‘solaris10.json’:\n\"iso_checksum_type\": \"sha1\",\nIt appears twice. Delete both of these lines.\n[3]\nOpen up a terminal and cd to where the ‘solaris10.json’ file is located. Execute the following command to create an updated Packer configuration from the json file:\n\npacker hcl2_upgrade solaris10.json\n\nYou should get a confirmation message such as:\nSuccessfully created solaris10.json.pkr.hcl. Exit 0\n[4]\nFollow step 5 of the Instructions and make sure VirtualBox or VMware is installed.\n[5]\nFrom where your solaris10.json is located, execute:\n\npacker build .\n\nThe automated build will now run for a while, with the console showing the commands as they are run.\nAs per step 7 of the Instructions, do not attempt to interact with the VM window. Even if it appears static, processes will be running in the background.\nWait for the build to finish.\n[6]\nComplete the remaining installation steps 8-10 from the Instructions.\nFor those using VirtualBox: you should have a successfully-imported virtual machine at this point. Before launching it, first choose ‘settings’. On the ‘system’ tab feel free to allocate some more base memory (staying within the recommended green band). On the ‘display tab’, similarly allocate some more video memory - this is important otherwise increasing the screen resolution later may fail.\n[7]\nLaunch the virtual machine and log in using the ‘rhub’ account as per the Instructions.\nChoose the Sun Java Desktop Environment (however much you are tempted to use the awesome CDE). Once you arrive at a desktop, right click and set the desired screen resolution. (Here, if not enough video memory was allocated in the previous step you may get a black screen. If you do not get back to a usable dektop, power off the VM and try again.)\n[8]\nOpen a terminal window and install the following packages from openCSW, the Solaris open source software repository, by issuing the following command:\n\nsudo pkgutil -y -i cmake gmake curl libcurl_dev libssh2_dev libssl_dev libxml2_dev libiconv_dev\n\nThese are utilities and system libraries that are required to install the various dependencies of ‘devtools’.\n[19]\n‘libgit2’ is required but not available on openCSW, and hence must be built. In a terminal window, execute the commands in the following instructions by Jeroen Ooms:\nhttps://gist.github.com/jeroen/4f13ff48596b449283ca98af7b95601d\nStart from # Download latest release as we have already installed the dependencies as part of the previous step.\n[10]\nFor the final step, load up a terminal window. Enter the following to set the environment variable:\n\nexport MAKE=gmake\n\nFrom the same terminal window, launch R:\n\nR\n\nAt the R prompt, proceed to install the ‘devtools’ package:\n\n\ninstall.packages(\"devtools\")\n\n\n\nYou will be prompted if you would like to use and create a personal library. Proceed with ‘yes’ both times.\nAll the dependencies of ‘devtools’ will now be downloaded and install will take a while.\nThe installation should complete successfully leaving you with a full R development environment on Solaris.\nBonus\nInstall the last released Firefox build 52.0esr for Solaris - this allows modern websites such as Github to load.\nOpen up a terminal and enter the following:\n\ncd Desktop\n\n# Download file\ncurl -OL https://ftp.mozilla.org/pub/firefox/releases/52.0esr/contrib/solaris_pkgadd/firefox-52.0esr.en-US.solaris-10-fcs-i386-pkg.bz2\n\n# Decompress file\nbzip2 -d firefox-52.0esr.en-US.solaris-10-fcs-i386-pkg.bz2\n\n# Install package\nsudo pkgadd -d ./firefox-52.0esr.en-US.solaris-10-fcs-i386-pkg\n\nRespond ‘yes’ to all install prompts.\nIt does not overwrite the bundled version, so set up a shortcut by right-clicking on the desktop, and select ‘Create Launcher’.\nFor ‘Name’ enter Firefox, for ‘Command’ enter /opt/sfw/lib/firefox/firefox\nDouble-click the new launcher icon on the desktop to bring up Firefox.\nPower off\nTo turn off the VM, open up a terminal window and issue:\n\nsudo poweroff\n\n–\n\nThis article (excluding the photograph) is licensed under CC BY 4.0\n\n\nCopyright, the R Consortium↩︎\n",
    "preview": "posts/14-r-on-solaris/r-on-solaris_files/figure-html5/index-1.png",
    "last_modified": "2022-02-13T15:48:23+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/12-oanda-studio/",
    "title": "R Shiny interface for the OANDA fxTrade API",
    "description": "ichimoku::oanda_studio()",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2021-07-26",
    "categories": [
      "R"
    ],
    "contents": "\n\nContents\nAbout ichimoku\nAbout the OANDA fxTrade API\nScreenshots\nOther functions\nLinks and further information\n\n\n\n\n\nShikokuchuo\nAbout ichimoku\nThe ichimoku R package1 provides tools for creating and visualising Ichimoku Kinko Hyo (cloud chart) strategies.\nIt features in the Empirical Finance CRAN Task View, and was selected as one of RStudio’s Top 40 New CRAN Packages for May 2021.\nThe latest version incorporates an interface to the OANDA fxTrade API2.\nAbout the OANDA fxTrade API\nOANDA is an authoritative source of foreign exchange data utilised by both governments and global corporations alike. OANDA offers a few APIs, including its rates for business, but the fxTrade API is perhaps the most comprehensive, built upon its retail and professional trading offering of the same name. Access to the fxTrade API is free but requires registration for a practice/demo account.\nThe API can be used for retrieving historical and live streaming price data for major currencies, metals, commodities, government bonds and stock indices. It is a rich source of financial data with excellent availability, for instance daily OHLC pricing data for major forex pairs from the start of 2005, and data granularity ranging from 5 seconds to monthly.\nFor the total list of over 120 covered instruments please see here.\nScreenshots\nClick on an image to view in full resolution.\nShowcased here is the function oanda_studio(), the implementation in R Shiny. As a Shiny app, the function may be called without specifying any parameters; the full range of options can be selected interactively from within the web interface.\nData is live and updates at the specified refresh rate (default of every 5 secs).\nThe cursor infotip provides an innovative overview of the data directly from the chart (can be turned on or off as desired).\n\n\nlibrary(ichimoku)\n\noanda_studio()\n\n\n\n\nOf course arguments for customisation can also be specified within the call to oanda_studio() itself. Demonstrating some further options below with Soybean futures:\n\n\noanda_studio(\"SOYBN_USD\", granularity = \"M5\", refresh = 10, price = \"B\", theme = \"dark\")\n\n\n\n\nOther functions\nOther functions to access the OANDA fxTrade API are included in the ichimoku package. These are standard R functions for retrieving data in tabular form and charting (not reliant on Shiny), and include:\noanda() to retrieve price data\noanda_stream() to stream a live data feed\noanda_chart() to plot real-time ichimoku cloud charts\nLinks and further information\nichimoku R package site: https://shikokuchuo.net/ichimoku/\nichimoku OANDA fxTrade API vignette: https://shikokuchuo.net/ichimoku/articles/xoanda.html\n\nGao, C. (2021), ichimoku: Visualization and Tools for Ichimoku Kinko Hyo Strategies. R package version 1.0.0, https://CRAN.R-project.org/package=ichimoku.↩︎\n‘OANDA’ and ‘fxTrade’ are trademarks owned by OANDA Corporation, an entity unaffiliated with the ichimoku package.↩︎\n",
    "preview": "posts/12-oanda-studio/oanda-studio_files/figure-html5/index-1.png",
    "last_modified": "2022-02-13T15:46:04+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/08-ichimoku/",
    "title": "ichimoku",
    "description": "R package for Ichimoku Kinko Hyo cloud charts",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2021-05-19",
    "categories": [
      "R",
      "Quantitative Finance"
    ],
    "contents": "\n\nContents\nExample\nInstallation\nPackage\nIchimoku Kinko Hyo \nInterpretation\nContext\n\n\n\n\n\nShikokuchuo\nAn implementation in R of the Ichimoku Kinkō Hyō (一目均衡表) charting system, also commonly known as ‘cloud charts’.\nThe technique is a refinement on candlestick charting, originating from Japan and now in widespread use in technical analysis worldwide. Translating to ‘one-glance equilibrium chart’, it allows the price action and market structure of financial securities to be determined ‘at-a-glance’.\nExample\nLoad package and sample data:\n\n\nlibrary(ichimoku)\nTKR <- sample_ohlc_data\n\n\n\nichimoku() to generate the ichimoku object:\n\n\ncloud <- ichimoku(TKR)\nsummary(cloud)\n\n\nichimoku object with dimensions (281, 12) \n\n            Max: 2020-07-14 [139.7]\nStart: 2020-01-02 [123]   End: 2020-12-24 [136]\n            Min: 2020-05-13 [119.1]\n\nCloud periods: 9 26 52 \nPeriodicity: 1 days \nTicker: TKR\n\niplot() for fully-interactive cloud charts:\n\n\niplot(cloud)\n\n\n\n\nplot() for static cloud charts:\n\n\nplot(cloud, window = \"2020-05/\", theme = \"solarized\")\n\n\n\nplot(cloud, window = \"2020-05/\", theme = \"dark\")\n\n\n\nplot(cloud, window = \"2020-05/\", theme = \"mono\")\n\n\n\n\nInstallation\nInstall the released version of ichimoku from CRAN:\ninstall.packages(\"ichimoku\")\nOr the latest development version from rOpenSci R-universe:\ninstall.packages(\"ichimoku\", repos = \"https://shikokuchuo.r-universe.dev\")\nPackage\nWebsite: https://shikokuchuo.net/ichimoku/ 1\nIchimoku Kinko Hyo 2\nThe system consists of the following chart lines added to a candlestick chart:\n転換線 Tenkan-sen [conversion line]: the mid-point of the highest high and lowest low for the past 9 periods (including the current period)\n基準線 Kijun-sen [base line]: the mid-point of the highest high and lowest low for the past 26 periods (including the current period)\n先行スパン1 Senkou span A [leading span A]: the mid-point of Tenkan-sen and Kijun-sen plotted ahead 26 periods (including the current period)\n先行スパン2 Senkou span B [leading span B]: the mid-point of the highest high and lowest low for the past 52 periods (including the current period), plotted ahead 26 periods (including the current period)\n遅行スパン Chikou span [lagging span]: the current period closing price plotted behind 26 periods (including the current period)\nThe 雲 kumo [cloud] is the area bounded by Senkou span A and Senkou span B (usually shaded on a chart).\nInterpretation\nIchimoku Kinkō Hyō can be translated as ‘one-glance equilibrium chart’. It is designed to allow the price action and market structure of financial securities to be determined ‘at-a-glance’ in a highly visual fashion.\nFor example in a strongly upwards-trending market, the candlesticks will be above the Tenkan-sen, which will be above the Kijun-sen, which will be above the cloud, and the Chikou span may not have anything above it.\nThe lines and the cloud represent dynamic support and resistance zones relative to the price candles. Generally the thicker the cloud, the tougher the support/resistance. In our previous example, if the price now reverts downwards, it can expect support first at the Kijun-sen, then the Tenkan-sen and finally the cloud itself.\nMore subtle interpretations involve the Chikou span in particular and its action in relation to the cloud lines as well as the candles.\nContext\nIchimoku analysis is the latest refinement in candlestick charting techniques, which also originated from Japan. Developed by 一目山人 Ichimoku, Sanjin, the pen name of 細田吾一 Hosoda, Goichi, his work was published in 1969 as the seminal 「一目均衡表」 [ichimoku kinkou hyou]. It gained popularity in Japan especially after the publication of Sasaki’s 「一目均衡表の研究」 [ichimoku kinkouhyou no kenkyuu] in 1996, and is now widely-used in technical analysis worldwide.\nThe time periods have traditionally been calculated as 9, 26 and 52 based on manual data analysis performed in Japan in a pre-computer age where there was a 6-day working week resulting in 26 average trading days in a month. Although this bears little relevance to the current day, the use of these time periods has persisted as an ‘industry norm’ or ‘accepted practice’.\nTo use other periods would be meaningless in a sense as everyone uses these parameters and ‘market psychology’ can and often does create its own realities, independent of any fundamentals. However, there is no reason for the technique not to evolve, and to reflect changing trading realities perhaps other parameters will become more relevant in the collective psychology.\nFinally, the use originated with daily candlesticks, and the most valid interpretation remains for daily data. However, it is equally used today for both shorter intra-day, e.g. 4-hour or hourly, and longer, e.g. weekly or monthly, charts.\n\nGao, C. (2021), ichimoku: Visualization and Tools for Ichimoku Kinko Hyo Strategies. R package version 1.2.4, https://CRAN.R-project.org/package=ichimoku.↩︎\nSasaki, H. 佐々木 英信 (1996), 一目均衡表の研究 [ichimoku kinkouhyou no kenkyuu]. Tokyo, Japan: Toushi Radar.↩︎\n",
    "preview": "posts/08-ichimoku/ichimoku_files/figure-html5/index-1.png",
    "last_modified": "2022-02-13T15:42:35+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/01-authenticating/",
    "title": "Authenticating photography using cryptographic hashing",
    "description": "A proof of concept using R",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2021-05-01",
    "categories": [
      "Photography",
      "Cryptography"
    ],
    "contents": "\n\nContents\nReproducible R code and authentification\nAs applied to a digital photography workflow\n\nReproducible R code and authentification\nR is an open source programming language popular amongst statisticians and data scientists. The power of the R framework is enhanced through the tens of thousands of packages contributed by the open source community that extends and enhances R. 1\nThe below code is a simple proof of concept of using cryptographic hashing as a method for authentification of original photographic files. The code simply retrieves the files in a certain folder and loads them into R using the imager 2 package and plots them, here on the page, but it could easily be another output device such as writing to jpeg or pdf. At the same time, the original file is run through a sha256 cryptographic hash from the openssl 3 package. sha256 is a one-way algorithm that takes an input and generates a hexadecimal sequence 64 long. As the input file may be arbitrarily large, it can easily be seen that the information loss in arriving at the hash precludes the possibility of going in the other direction i.e. retrieving the original data from the hash. The properties of the hashing algorithm include that small changes to the input file can result in completely different hash values. The chances of collision i.e. two different data files generating the exact same hash is vanishingly small.\n\n\nphotos <- file.path(\"_images\", list.files(\"_images\"))\ndevelop <- function(x) {\n  plot(imager::load.image(x), axes = FALSE)\n  paste0(openssl::sha256(file(x)))\n}\npar(mar = c(0, 0, 0, 0))\ndata.frame(sha256 = do.call(rbind, lapply(photos, develop)))\n\n\n\n                                                            sha256\n1 cba0450d38b74f2585868d2aa026a96de735a8f73a54889366d62bbdfdcc8661\n2 a63b055e11765cf36fa065be413b0bb5deb89d6cfba0c9feac7b9946e9c76ece\n3 f06eb35ea2bea1166e3147d30a846069fa5fd969717185d3e27821cea9257999\n4 0e6cc2bf63313153c6f3aa3206a0dc1d3eb41e6a5a570b48ea5021e437672f99\n\n\nNote: sha256 hashes are of the original files. Saving and hashing the images on this page would produce completely different hashes.\nThe output image along with the sha256 hash of the original can then be published together. The photographer is then able to freely share their work, which does not then need to be downsized, degraded or watermarked, as long as the data of the original file has undergone some form of transformation (that is not trivially reversible) to produce the output. The hash is the proof of authenticity of the original, which only the original artist possesses.\nTo prove authorship, the artist just needs to run the above function again, which would produce the same output and same hash values, and is an example of the benefits of reproducibility in writing R code.\nAs applied to a digital photography workflow\nEquivalent to the example demonstrated here, the workflow of digital photographers is often to take a RAW camera file, and perform edits using photo processing software 4, before generating an output. Software generally keeps the RAW file intact as a form of “digital negative”, but adds the edits in a layer stored separately either as a “sidecar” file or in a database etc. depending on the software. Photographers often take the output and store a best quality version as their “master”.\nOur approach would differ in treating the RAW file as the “original”, which allows a high-quality output to then be published along with the sha256 of the RAW file. The artist retains the RAW file, along with the sidecar file and software that generates the output, as proof of authorship. This works of course only where the artist can ensure reproducibility of the output, and using open source software where the edits are stored transparently in a human-readable format would afford greater confidence in such a workflow.\n\nThe largest listing of packages may be found at The Comprehensive R Archive Network: https://cloud.r-project.org/↩︎\nimager R package: https://dahtah.github.io/imager/↩︎\nopenssl R package: https://github.com/jeroen/openssl↩︎\nA popular example of such photo-editing software is the open source Darktable https://www.darktable.org/↩︎\n",
    "preview": "posts/01-authenticating/authenticating_files/figure-html5/index-1.png",
    "last_modified": "2022-02-14T22:50:38+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  }
]
